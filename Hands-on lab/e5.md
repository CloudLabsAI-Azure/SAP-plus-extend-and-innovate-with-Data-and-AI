## Exercise 5: Train a regression model to predict incoming cashflow using Azure Machine Learning Studio

### Estimated Duration: 50 minutes

## Lab Scenario

In this exercise, you will learn how to connect Azure Machine Learning to sales data stored in Azure Data Lake Storage. You will then use this connection to train a predictive model aimed at forecasting incoming cash flow, leveraging the robust capabilities of Azure Machine Learning for data analysis and prediction.

## Lab Objectives

After completing this lab, you will be able to:

- Task 1: Retrieve the access key for the Azure Data Lake Storage account
- Task 2: Create an Azure Machine Learning datastore
- Task 3: Create and run an Automated ML job
- Task 4: Deploy the best model as a web service

### Task 1: Retrieve the access key for the Azure Data Lake Storage account

In this task, you will retrieve the access key for the Azure Data Lake Storage account. This involves navigating to the Azure Portal, selecting the relevant storage account within the specified resource group, and copying the access key from the Access keys section for use in subsequent tasks.

1. Navigate back to the Azure Portal, open the lab resource group **sap_plus_extend_and_innovate** then search for and select the Storage account **sapadls{SUFFIX}**.

    ![The resource group listing displays with the sapadls{SUFFIX} Storage account resource selected.](media/ap_adlsrglist.png "Resource group listing")

2. From the left menu, select **Access keys**. Below the **key1** heading, select the **Show** button next to the Key field. Use the Copy button in the field to record this value for a future task.

    ![The Access keys screen displays for the storage account with the copy button next to the key1 Key field highlighted.](media/ap_adlsaccesskeycopy.png "Copy key1 Key value")

### Task 2: Create an Azure Machine Learning datastore

In this task, you will create an Azure Machine Learning datastore by configuring it to use Azure Blob Storage. You will provide necessary details such as the datastore name, storage account, and authentication key, and then create the datastore in the Azure Machine Learning workspace.

1. In the Azure Portal, open the lab resource group **sap_plus_extend_and_innovate** then search for and select the Azure Machine Learning resource **sap-ml-ws**.

    ![The resource group listing displays with the sap-ml-ws item highlighted.](media/ap_amlwsrglist.png "Resource Group list")

2. On the Azure Machine Learning Overview screen, select the **Studio web URL** to open the workspace.

    ![The Azure Machine Learning Overview screen displays with the Studio web URL hyperlink selected.](media/ap_launchamlworkspace.png "Launch AML Studio")

3. From the left menu, select **Data** beneath the **Assets** header. On the **Data** screen, select the **Datastores** tab, then select **+ Create**.

   ![AML Studio displays with Data selected from the left menu, the Datastores tab is selected with the Create button highlighted.](media/amls_datastoremenu.png "AML Studio create new datastore")

4. On the Create datastore blade, fill in the form as follows then select **Create**.

    | Field | Value |
    |-------|-------|
    | Datastore name | Enter `sales_payments_full_adls` |
    | Datastore type | Select **Azure Blob Storage** |
    | Account selection method | Select **From Azure subscription** |
    | Subscription ID | Select the lab subscription |
    | Storage account | Select **sapadls{SUFFIX}(sap_plus_extend_and_innovate)** |
    | Blob container | Select **sales-payment-parquet** |
    | Save credentials with the datastore for data access | Select **Yes** |
    | Authentication type | Select **Account key** |
    | Account key | Enter the storage account key obtained in the previous task |
    | Use workspace managed identity for data preview and profiling in Azure Machine Learning studio | Toggle off |

    ![The Create datastore blade displays with a form populated with the preceding values.](media/amls_newdatastoreform.png "Create datastore")

### Task 3: Create and run an Automated ML job

In this task, you will create and run an Automated Machine Learning (AutoML) job in Azure Machine Learning Studio to predict incoming cash flow. You'll configure the AutoML job, choose the dataset, set up a compute cluster, and submit the training job. After training, you will deploy the best model as a web service and monitor its deployment status until it is successfully completed.

1. In Azure Machine Learning Studio, select **Automated ML** from the left menu.

    ![A portion of the left menu of Azure Machine Learning studio displays with the Automated ML item highlighted.](media/amls_automatedml_menu.png "Automated ML")

1. On the Automated ML screen, select **+ New Automated ML job** from the toolbar menu.

    ![The Automated ML screen toolbar menu displays with the + New Automated ML job button highlighted.](media/amls_newautomlrun_menu.png "New Automated ML job")

1. On the **Submit an Automated ML job** page, enter the following details:

    - **Job name**: Keep the default **(1)**
    - **New experiment name**: Enter **predict-incoming-cashflow (2)**
    - Select **Next (3)**

        ![The Automated ML screen toolbar menu displays with the + New Automated ML job button highlighted.](media/sales-pull.png "New Automated ML job")

1. Under the **Task type & data** page, enter the following details:

    - **Select task type**: Select **Regression**
    - Under **Select data** select **+ Create**.

1. On the Create data asset Data type form, name the dataset `sap-sales-payments-full`, and select **Type** as **Tabular**. Select **Next**.

    ![The Create data asset Data type form displays with sap-sales-payments-full entered in the Name field.](media/13-09-2024.png "New data asset Data type form")

1. On the Create data asset Data source selection step, select **From Azure storage**. Select **Next**.

    ![The Create data asset Data type form displays with sap-sales-payments-full entered in the Name field.](media/13-09-2024(1).png "New data asset Data type form")

1. On the Create data asset Storage type step, select the **sales_payments_full_adls** item as the datastore. Select **Next**.

    ![The Create data asset Storage type step displays with sales_payments_full_adls selected as the datastore.](media/amlms_dataasset_storagetype.png "Create data asset datastore selection")

1. On the Create data asset Storage path step, select the **dbo.SalesPaymentsFull.parquet** file for the storage path. Select **Next**.

    ![The Create data asset Storage path step displays with dbo.SalesPaymentsFull.parquet selected as the storage path.](media/amlms_dataset_datastoreselection.png "Create data asset storage path selection")  

1. On the Create data asset Settings step, review the data from the parquet file, then select **Next**.

    ![The Create data asset Storage path step displays with a preview of data contained within the parquet file.](media/amlms_dataasset_settings_data_preview.png "Preview parquet file data")

1. On the Create data asset Schema step, toggle the following fields off so that they are not included in the dataset then select **Next**:
   - SALESDOCUMENT
   - BILLINGDOCUMENTDATE
   - PAYMENTDATE
   - SALESGROUP
   - SALESOFFICE

        ![The Create data asset Schema step screen displays with the specified fields toggled to not be included. The Next button is highlighted.](media/amls_dataset_schema.png "Data asset Schema")

1. Review the settings and click on **Create**.

   ![The Create data asset Data type form displays with sap-sales-payments-full entered in the Name field.](media/13-09-2024(2).png "New data asset Data type form")

1. On the Select data asset step of the Create a new Automated ML job screen, refresh the data asset table.

    ![The Select data asset step screen displays with the Refresh button highlighted.](media/amls_dataassetselection.png "Select data asset step")

12. On the Select data asset step, select **sap-sales-payments-full** from the list and select **Next**.

    ![The Select data asset screen displays with the sap-sales-payments-full item selected.](media/amls_automlrun_selectdataset_sap.png "Select data asset step")

1. On the **Task settings** page, select **PAYMENTDELAYINDAYS** as a **Target column**. Select **Next**.

1. On the **Compute** page, **Select compute type** as **Compute cluster**. Select the **+ New** button below the **Select Azure ML compute cluster** field.

1. On the Create compute cluster blade Virtual machine step, accept the defaults, and select **Next**.

    ![The Virtual machine step screen displays with the Next button highlighted.](media/amls_newcomputecluster_defaultspecs.png "Default virtual machine")

1. On the Create compute cluster blade Advanced settings, fill in the form as follows then select **Create**. It takes a few moments for the cluster to be provisioned.

    | Field | Value |
    |-------|-------|
    | Compute name | Enter `automlcompute` |
    | Maximum number of nodes | Enter `3` |

    ![The Compute cluster Advanced Settings displays with automlcompute entered in the Compute name and the Maximum number of nodes is set to three.](media/amls_compute_advancedsettings.png "Compute cluster Advanced Settings")

1. On the Compute job step, fill in the form as follows, then select **Next**.

    | Field | Value |
    |-------|-------|
    | Select compute type | Select **Compute cluster** |
    | Select Azure ML compute cluster | Select **automlcompute** |

1. Select **Submit training job**.

1. The job is then created and opened in the browser. Use the **Refresh** button to monitor the current state.

    ![The Automated ML job screen displays with a status of Running. The Refresh button is highlighted.](media/amls_automljob_running.png "Running Automated ML job")

    > **Note**: Training will take approx 1-2 hours. Proceed to [Exercise 7](#exercise-7-visualize-historical-data-with-power-bi) and return here once completed.

    > **Congratulations** on completing the task! Now, it's time to validate it. Here are the steps:
    > - Hit the Validate button for the corresponding task. If you receive a success message, you can proceed to the next task. Alternatively, you can navigate to the Lab Validation Page, from the upper right corner in the lab guide section.
    > - If not, carefully read the error message and retry the step, following the instructions in the lab guide. 
    > - If you need any assistance, please contact us at labs-support@spektrasystems.com. We are available 24/7 to help you out.

      <validation step="b3e65a85-1558-4f82-b557-71b5c10517bd" />

### Task 4: Deploy the best model as a web service

1. Once the Automated ML job indicates a status of **Completed**, in the Best model summary card on the screen, select the link beneath the **Algorithm name** heading.

    ![The Automated ML job screen displays with a Status of Completed. The link below Algorithm name is highlighted.](media/amls_automljob_complete.png "Completed Automated ML job")

2. On the Model screen, expand the **Deploy** item in the toolbar menu and select *Web service**.

    ![The Model screen displays with the Deploy item expanded in the toolbar menu and the Deploy to web service option highlighted.](media/amls_model_deploy_menu.png "Deploy model as web service")

3. On the Deploy a model blade, complete the form as follows then select **Deploy**.

    | Field | Value |
    |-------|-------|
    | Name | Enter `predict-incoming-cashflow-svc` |
    | Compute type | Select **Azure Container Instance** |

    ![The Deploy a model blade displays with a form populated with the preceding values.](media/amls_model_deploy_settings.png "Deploy a model")

4. On the Model screen, monitor the Deploy status at the bottom of the Model summary card. It will indicate a status of **Completed** in a few minutes time. Please wait for the message to turn from **Running** to **Succeeded**.

    ![The Model screen displays with the Deploy status indicating Running.](media/amls_modelsvc_deploying.png "Model deployment status")

5. Select the link below **Deploy status** to go to the deployed service endpoint screen.

<!-- 6. On the predict-incoming-cashflow-svc endpoint screen, select the **Test** tab. Replace the contents of the input data with the following and select **Test**.

    ```json
    {
        "Inputs": {
            "data": [
            { 
                "CUSTOMERNAME": "Westend Cycles",
                "CUSTOMERGROUP": "Z1",
                "BILLINGCOMPANYCODE": 1710,
                "CUSTOMERACCOUNTGROUP": "KUNA",
                "CREDITCONTROLAREA": "A000",
                "DISTRIBUTIONCHANNEL": 10,
                "ORGANIZATIONDIVISION": 0,
                "SALESDISTRICT": "US0003",
                "SALESORGANIZATION": 1710,
                "SDDOCUMENTCATEGORY": "C",
                "CITYNAME": "RALEIGH",
                "POSTALCODE": "27603"
            },
            { 
                "CUSTOMERNAME": "Skymart Corp",
                "CUSTOMERGROUP": "Z2",
                "BILLINGCOMPANYCODE": 1710,
                "CUSTOMERACCOUNTGROUP": "KUNA",
                "CREDITCONTROLAREA": "A000",
                "DISTRIBUTIONCHANNEL": 10,
                "ORGANIZATIONDIVISION": 0,
                "SALESDISTRICT": "US0004",
                "SALESORGANIZATION": 1710,
                "SDDOCUMENTCATEGORY": "C",
                "CITYNAME": "New York",
                "POSTALCODE": "10007"
            }
            ]
        },
        "GlobalParameters": 1.0
    }
    ```

    ![The predict-incoming-cashflow-svc endpoint screen displays with the test data in the text box. The results of the call are also displayed.](media/amls_endpoint_test.png "Test service deployment endpoint") -->

## Summary

In this exercise, you have retrieved the access key for the Azure Data Lake Storage account, created an Azure Machine Learning datastore to connect to the data, and set up and ran an Automated Machine Learning job. Finally, you deployed the best model from the Automated ML job as a web service.

## You have successfully completed this exercise. Select **Next >>** to proceed to the next one.
